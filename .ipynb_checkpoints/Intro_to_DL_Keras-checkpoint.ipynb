{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import regularizers\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train a hand-written digit classifier\n",
    "\n",
    "We will use the famous handwritten digit dataset MNIST.  This is a very popular data set for training small networks, since the data typically fits in local memory, and you can do convolutional networks with it.  This time, though, we will not be doing convolutional networks.  We will just be training a \"multi-layer perceptron\" or a \"fully-connected network\", keeping this as simple as possible to highlight how easy it is to use Keras.  We'll take each step in turn:\n",
    "- Data\n",
    "- Loss\n",
    "- Optimizer\n",
    "- Model\n",
    "- Callbacks\n",
    "- (Regularization)\n",
    "\n",
    "\n",
    "# Data\n",
    "MNIST is so famous it comes packaged with keras.  Let's take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_feats, train_labels), (valid_feats, valid_labels) = mnist.load_data()\n",
    "train_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so in our training set we have 60k handwritten digits.  Each digit is an image of size 28 x 28.  Let's look at one of the images just to see what we're dealing with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 42,  54, 213, 241,  95,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,  93, 254, 115,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,  93, 255, 115,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 176, 254, 115,   0,   0,   0,   0,   0],\n",
       "       [  0,  28, 215, 254, 115,   0,   0,   0,   0,   0],\n",
       "       [134, 240, 253, 228,  40,   0,   0,   0,   0,   0],\n",
       "       [206, 254, 254,  68,   0,   0,   0,   0,   0,   0],\n",
       "       [ 29, 211, 253, 147,  21,   0,   0,   0,   0,   0],\n",
       "       [  0,  21, 180, 245, 228, 165, 116, 116, 116, 116],\n",
       "       [  0,   0,   0,  44, 119, 202, 253, 254, 253, 253]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feats[558][10:20, 10:20] # this is just a slice of the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAI4CAYAAACiBwlnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niyRJGsq/7facEetJRU0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this is what we get if we plot the data with the pixel densities\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(train_feats[i], cmap='Greys', interpolation='none')\n",
    "    plt.title(\"Class {}\".format(train_labels[i]))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handwritten digits are inherently 2-D, in that they have regular two-dimensional structure.  To better deal with that structure, we'll use Convolutional networks later, but for now what we'll do is just treat every pixel as if it is its own feature, and as the question, can a neural network learn the complicated relationships that exist between individual pixel locations?  \n",
    "\n",
    "So we'll flatten all the features so each number is a one-dimensional vector of length 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feats = train_feats.reshape(60000, 784)\n",
    "valid_feats = valid_feats.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels are integers corresponding to the actual digits.  We will need to one-hot-encode them.  (ie make them categorical, or dummy variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now let's make the labels categorical\n",
    "train_labels = pd.get_dummies(train_labels)\n",
    "valid_labels = pd.get_dummies(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9\n",
       "0  0  0  0  0  0  1  0  0  0  0\n",
       "1  1  0  0  0  0  0  0  0  0  0\n",
       "2  0  0  0  0  1  0  0  0  0  0\n",
       "3  0  1  0  0  0  0  0  0  0  0\n",
       "4  0  0  0  0  0  0  0  0  0  1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing is we should probably normalize the data.  For now lets just scale it to between 0 and 1 by dividing by the max value (255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feats = train_feats / 255\n",
    "valid_feats = valid_feats / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could think about normalizing instead of just scaling, but let's call it good for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss\n",
    "\n",
    "Since we are classifying each example as one of many different classes (digits), we will be attempting to minimize the categorical crossentropy function described in the lecture notes.  We'll see later how to make custom loss functions, but for now since we are using a common loss, we can just use the string identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = 'categorical_crossentropy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer\n",
    "We'll use the common optimizer \"Adam\" as described in the lectures.  Again, since it is a very common optimizer, we can just use the string identifier and Keras will initialize the Adam optimizer with default parameters when we compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = 'adam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model (activations)\n",
    "\n",
    "Great!  We're now ready to build, compile, and fit our Keras model.  We'll use the Keras functional API since we are not savages\n",
    "\n",
    "Our model will consist of an input layer, two Dense Layers, and a 10-dimensional output layer for predicting the digits.  For each layer we will consider what sort of activation functions to use.  For the hidden layers we'll use the reLU activation, which is fairly standard default at the moment.  The final activation layer will be a softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(784,))\n",
    "x = Dense(256, activation='relu')(inputs)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compile the model, telling it which optimizer and loss to use.  \n",
    "We'll also tell it to calculate accuracy at every epoch\n",
    "\n",
    "Then we'll print out a handy keras summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=opt,\n",
    "             loss=loss)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll fit the model.  The things we need to give the fit function are: Training data, the number of epochs to run, and the batch size.  \n",
    "\n",
    "**epochs** An epoch is a somewhat arbitrary division of training, but for small closed data sets usually an epoch is an entire run through the training data.  You can specify smaller epochs\n",
    "\n",
    "Optionally we can also give it validation data, and it will calculate metrics on that data set as well\n",
    "\n",
    "If you want Keras to split the training data for you automatically, you can just pass it the parameter validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.2220 - val_loss: 0.1149\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0832 - val_loss: 0.0745\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0544 - val_loss: 0.0844\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0425 - val_loss: 0.0706\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0312 - val_loss: 0.0761\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0249 - val_loss: 0.0789\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0209 - val_loss: 0.0811\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0201 - val_loss: 0.0782\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0156 - val_loss: 0.0846\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0170 - val_loss: 0.0887\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0132 - val_loss: 0.0861\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 55us/step - loss: 0.0104 - val_loss: 0.0919\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0124 - val_loss: 0.0865\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0133 - val_loss: 0.0890\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0094 - val_loss: 0.1005\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0096 - val_loss: 0.0943\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0098 - val_loss: 0.1052\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0096 - val_loss: 0.1022\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0060 - val_loss: 0.0931\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0088 - val_loss: 0.1038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1171fe9e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "model.fit(train_feats, train_labels,\n",
    "         epochs=n_epochs,\n",
    "         batch_size=64,\n",
    "         validation_data = (valid_feats, valid_labels),\n",
    "         verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have some data about the accuracy of the model but just for fun let's make a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 969,    0,    2,    0,    0,    3,    3,    1,    2,    0],\n",
       "       [   1, 1113,    2,    4,    0,    0,    4,    3,    8,    0],\n",
       "       [   2,    0, 1015,    2,    1,    0,    2,    4,    5,    1],\n",
       "       [   0,    0,    3,  991,    0,    3,    0,    6,    4,    3],\n",
       "       [   5,    0,    1,    0,  943,    0,    3,    9,    1,   20],\n",
       "       [   2,    0,    0,    6,    0,  873,    3,    3,    2,    3],\n",
       "       [   0,    1,    1,    1,    1,    4,  948,    1,    1,    0],\n",
       "       [   0,    1,    5,    2,    0,    0,    0, 1014,    2,    4],\n",
       "       [   3,    0,    5,    5,    0,    5,    1,    3,  947,    5],\n",
       "       [   2,    2,    1,    2,    3,    2,    0,    2,    0,  995]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pred = np.argmax(model.predict(valid_feats), 1)\n",
    "valid_labels_dense = np.argmax(valid_labels.values, 1)\n",
    "confusion_matrix(valid_labels_dense, valid_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks\n",
    "\n",
    "Callbacks are extremely useful in Keras.  They allow you to specify any particular action you want done at periodic intervals, typically at the end of each epoch.  Common options include:\n",
    "\n",
    "- Checkpoint the model by saving it periodically\n",
    "- Keep track of the model with the best validation performance\n",
    "- write to a log.  TENSORBOARD\n",
    "- Calculate custom metrics that can't be calculated over batches (like auc)\n",
    "\n",
    "\n",
    "Let's retrain the above model, but using a Tensorboard callback.  We'll also remake the model and add in another metric, 'accuracy', for keras to keep track of and log.\n",
    "\n",
    "To access tensorboard, run \"tensorboard --logdir ..logs/\" replacing ..logs/ with whatever you set your log directory to be below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change the name of the callback every time you run it so you don't write multiple training runs to the same log\n",
    "tb_callback = TensorBoard('../logs/mnist_model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 269,322\n",
      "Trainable params: 269,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.0097 - acc: 0.9969 - val_loss: 0.0997 - val_acc: 0.9823\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.1255 - val_acc: 0.9782\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0098 - acc: 0.9969 - val_loss: 0.1004 - val_acc: 0.9830\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.0972 - val_acc: 0.9833\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0089 - acc: 0.9975 - val_loss: 0.1196 - val_acc: 0.9794\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0076 - acc: 0.9977 - val_loss: 0.1078 - val_acc: 0.9838\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.1153 - val_acc: 0.9817\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0094 - acc: 0.9974 - val_loss: 0.1068 - val_acc: 0.9826\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0079 - acc: 0.9976 - val_loss: 0.1085 - val_acc: 0.9816\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0048 - acc: 0.9988 - val_loss: 0.1249 - val_acc: 0.9787\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0062 - acc: 0.9980 - val_loss: 0.1129 - val_acc: 0.9832\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.1197 - val_acc: 0.9803\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.1317 - val_acc: 0.9804\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0073 - acc: 0.9979 - val_loss: 0.1121 - val_acc: 0.9826\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.1285 - val_acc: 0.9806\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.1259 - val_acc: 0.9810\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0077 - acc: 0.9979 - val_loss: 0.1186 - val_acc: 0.9823\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.1573 - val_acc: 0.9774\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0068 - acc: 0.9982 - val_loss: 0.1462 - val_acc: 0.9804\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.1379 - val_acc: 0.9802\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0040 - acc: 0.9988 - val_loss: 0.1503 - val_acc: 0.9804\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s 64us/step - loss: 0.0080 - acc: 0.9981 - val_loss: 0.1308 - val_acc: 0.9835\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0062 - acc: 0.9982 - val_loss: 0.1437 - val_acc: 0.9794\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.0062 - acc: 0.9984 - val_loss: 0.1216 - val_acc: 0.9826\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0077 - acc: 0.9981 - val_loss: 0.1340 - val_acc: 0.9816\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0066 - acc: 0.9982 - val_loss: 0.1271 - val_acc: 0.9839\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.1351 - val_acc: 0.9818\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s 58us/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.1373 - val_acc: 0.9810\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.0072 - acc: 0.9984 - val_loss: 0.1389 - val_acc: 0.9829\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 61us/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.1423 - val_acc: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1171fe940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=opt,\n",
    "             loss=loss, \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(train_feats, train_labels,\n",
    "         epochs=30,\n",
    "         batch_size=64,\n",
    "         validation_data = (valid_feats, valid_labels),\n",
    "         callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "Regularization is a huge part of deep learning, and we'll spend A LOT more time talking about it.  You should see that the model we have trained is overfit to the training set. But for now with what we've learned so far, it may be useful to try some regularization.\n",
    "\n",
    "- **Limiting model capacity.** Models with fewer parameters are less able to overfit.  Limit model capacity, usually by decreasing the number of layers or the number of nodes per layer.\n",
    "- **Early stopping.** The longer you train, the more likely the model will memorize noise between the training set and the labels.  Monitor validation metrics, and if they start getting bad while the training metrics continue to improve, you may want to stop training there.  In Keras, often \"early stopping\" is handled by callbacks which can either save models periodically (so you can get the best ones from the past if the model starts overfitting), or by dropping the learning rate progressively to zero as the validation metrics get worse and worse.\n",
    "- **L1, L2 regularization** Add a penalty for high weights to the loss.  In practice this is less common than it is in simple linear/logistic regression, but it is valid and still used.\n",
    "\n",
    "\n",
    "In deep learning practice, much of your time will be spent experimenting with regularization strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.4579 - acc: 0.9076 - val_loss: 0.2847 - val_acc: 0.9514\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.2781 - acc: 0.9521 - val_loss: 0.2428 - val_acc: 0.9608\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.2342 - acc: 0.9622 - val_loss: 0.2239 - val_acc: 0.9638\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.2111 - acc: 0.9672 - val_loss: 0.1987 - val_acc: 0.9678\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1947 - acc: 0.9696 - val_loss: 0.1940 - val_acc: 0.9681\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1799 - acc: 0.9730 - val_loss: 0.1858 - val_acc: 0.9682\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.1727 - acc: 0.9732 - val_loss: 0.1755 - val_acc: 0.9723\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1658 - acc: 0.9745 - val_loss: 0.1714 - val_acc: 0.9722\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1608 - acc: 0.9756 - val_loss: 0.1692 - val_acc: 0.9701\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1552 - acc: 0.9762 - val_loss: 0.1625 - val_acc: 0.9725\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.1502 - acc: 0.9774 - val_loss: 0.1680 - val_acc: 0.9681\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1465 - acc: 0.9778 - val_loss: 0.1552 - val_acc: 0.9747\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1452 - acc: 0.9784 - val_loss: 0.1548 - val_acc: 0.9733\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1417 - acc: 0.9781 - val_loss: 0.1725 - val_acc: 0.9669\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1384 - acc: 0.9787 - val_loss: 0.1480 - val_acc: 0.9758\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1369 - acc: 0.9794 - val_loss: 0.1538 - val_acc: 0.9748\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1342 - acc: 0.9808 - val_loss: 0.1488 - val_acc: 0.9763\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.1326 - acc: 0.9801 - val_loss: 0.1382 - val_acc: 0.9775\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.1310 - acc: 0.9802 - val_loss: 0.1380 - val_acc: 0.9776\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.1284 - acc: 0.9806 - val_loss: 0.1422 - val_acc: 0.9749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a42a49e48>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_callback = TensorBoard('../logs/mnist_model3')\n",
    "\n",
    "#initialize an l2 regularization\n",
    "l2_reg = regularizers.l2(.001)\n",
    "\n",
    "inputs = Input(shape=(784,))\n",
    "# go down to layer size 64.  \n",
    "# Note what happens to the number of model parameters in the summary\n",
    "\n",
    "x = Dense(64, activation='relu', kernel_regularizer=l2_reg)(inputs)\n",
    "x = Dense(64, activation='relu', kernel_regularizer=l2_reg)(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=opt,\n",
    "             loss=loss, \n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# go down to 20 epochs\n",
    "model.fit(train_feats, train_labels,\n",
    "         epochs=20,\n",
    "         batch_size=64,\n",
    "         validation_data = (valid_feats, valid_labels),\n",
    "         callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the loss and validation loss above or in Tensorboard. Is the model less overfit?  Was there enough regularization?  Too much?  Just right?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
