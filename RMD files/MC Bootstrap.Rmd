---
title: "Bootstrapping with monte carlo error analysis!"
author: "Tyki Wada"
date: "3/6/2018"
output: html_document
---

We oftentimes undermine the power that parameter estimates have in predicting probabilities of outcomes. Sometimes, we just don't have enough data to find out a confidence estimate and interval of an outcome. Other times, we lack information to perform accurate hypothesis tests of statistical significance. These situations usually lead to needing non-parametric methods to figure out likelihood estimates of certain outcomes with the limited information we have!

Fortunately, we have the monte carlo method to give us a good gist. Monte carlo sampling is a technique that allows for estimates to follow the law of large numbers, creating a central limit distribution. In other words, MC takes a random sample of certain events (estimates) over and over and over and over again to obtain numerical events from uncertainty. 

![](https://thumbs.gfycat.com/InbornTerrificAvocet-size_restricted.gif)

One type of monte carlo sampling is the bootstrap technique (this is something that I will go over in-depth when I cover random forest models in a couple of months). Bootstrapping is one of the most useful procedures in determining confidence interval parameter estimates and is a sampling technique with replacement. This means, that every time an object is sampled, it is replaced back with the same probability of independant occurance. This is especially useful when we have known/estimated probabilities of certain outcomes and we are testing with limited amounts of data. Bootstrapping has been known to be valuable in dealing with optimization when there may be heteroscedacity (errors are not normally distributed) and distributional assumptions may not be met.

In short, it's a ridiculously useful technique to create more data when we have just partial information. Well then, let's take a look at some coding!

===================================

At first, I was going to take a look at some true/false outcomes (ie. poisson distribution), but I thought it might be nicer to look at more complex situations.


Here's a hypothetical situation where the bootstrap & monte carlo technique may be useful:

  - Suppose your company has 4 sales areas that have a history of closing a certain probability of deals. Let's call these divisions A, B, C, and D. 

  - With phone rates being 2 cents a call, the manager was worried that their area selections are becoming obsolete and that they are going to lose revenue.

  - Because past data has shown that at least 4 percent of people who answer calls buy your product (On average, one sale makes about $199), the manager has decided that they wanted to reevaluate how costly each phone call would be and see how many calls it will take to get at least one of every single area to respond. 

  - After repeated data collection, we have observed that each division has respective probabilities of c("A" = 0.10,"B" = 0.25,"C" = 0.25,"D" = 0.40) people answering phone calls. 


**What is our estimated profit/per call?**

**Are these collective areas profitable before all fixed and variable costs (taxes, overhead, and employee compensation)?**

**Is this a valid measure of area performance?**

Alright, let's get going already. First, I'll call out the beloved `dplyr` package to help me with this function. I honestly don't need it, but it makes this code a little more fun to work with. Well, since we are looking at how many tries it takes until we succeed on getting at least one call from each area. This is a great example of a compounded version of a negative binomial! For this problem, Instead of starting off each individual area and performing an rnbinom, I decided to stick them all into one sample and bootstrap it. I decided to do this because I wanted to see what the estimated profit per call was if we were calling each area at once. One large flaw with this technique is that all areas comprise the whole sample space and do not account for the compliment of the intersect of all values. Nevertheless, bootstrapping actually allows us to resample, indepdndently, without replacement, thus bringing the probability of getting at least one of each call closer to the true values (0.10, 0.25, 0.25, 0.40). 

I also toyed with changing the boolean *TRUE* to a character and character matching twice -once with `grepl` to produce the T, second by using `matches` to match the TRUE with itself. These were marked with a counter until the while loop marked every area as TRUE.

This procedure is run n times indicating the total number of monte carlo samples to go through to perform the count for how many calls it takes for us to get an answer from all four areas.

```{r}
library(dplyr)

numcall4 <- function(n=100) {
tha.calls <-c()
for (j in 1:n) {
  count <- 0
  A <- FALSE
  B <- FALSE
  C <- FALSE
  D <- FALSE
  while (!(A & B & C & D)) {
    count <- count + 1
    num.box <- sample(c("A", "B", "C", "D"), replace = TRUE, prob = c(0.10, 0.25, 0.25, 0.40))
      # just for fun, I did a character match with the boolean TRUE
    if (0 < sum(matches(match = "TRUE",vars = as.character(grepl("A",num.box))))) {
      A <- TRUE
    } else if (0 < sum(matches(match = "TRUE",vars = as.character(grepl("B",num.box))))) {
      B <- TRUE
    } else if (0 < sum(matches(match = "TRUE",vars = as.character(grepl("C",num.box))))) {
      C <- TRUE
    } else if (0 < sum(matches(match = "TRUE",vars = as.character(grepl("",num.box))))) {
      D <- TRUE
    }
  }
  tha.calls[j] <- sum(count)
}
hist(tha.calls)
print(mean(tha.calls)) # about 40
}

numcall4()
```
The histogram clearly shows a negative binomial pattern with a low probability and an estimate of about 40. Now that we have a function that gives us a MC estimate of the number of calls it takes, next we can assess the profitability of each outcome and check the confidence interval of that estimate.

```{r}
sale.prob <- .04 # probability of completing a sale/total answered phone calls.
ppc <- .02 # price per call
avprofit <- 199 # average profit
nReps <- 100 # number of repetitions

```


```{r}
ptm <- proc.time()  # Start the clock!

check <- c()
calls <- c()
for (i in 1:nReps) {
av_calls[i]<- numcall4()
check[i] <- sale.prob*av_calls[i]*avprofit - av_calls[i]*ppc
}
proc.time() - ptm   # Stop the clock

length(check)
mean(av_calls)
mean(check)
```

```{r}
ave_calls <- mean(av_calls)
short_profit <- mean(check)
short_profit/ave_calls 
# this means we make 7.94 cents on average per call that goes through all 4 areas.


hist(check)
mc.err <- quantile(check,c(.025,.975))
abline(v=mc.err,col='red')

c(mc.err[1],"estimate"=short_profit,mc.err[2])
```

