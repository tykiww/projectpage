---
title: "Bootstrapping with monte carlo error analysis!"
author: "Tyki Wada"
date: "3/6/2018"
output: html_document
---

We oftentimes undermine the power that parameter estimates have in predicting probabilities of outcomes. Sometimes, we just don't have enough data to find out a confidence estimate and interval of an outcome. Other times, we lack information to perform accurate hypothesis tests of statistical significance. These situations usually lead to needing non-parametric methods to figure out likelihood estimates of certain outcomes with the limited information we have!

Fortunately, we have the monte carlo method to give us a good gist. Monte carlo sampling is a technique that allows for estimates to follow the law of large numbers, creating a central limit distribution. In other words, MC takes a random sample of certain events (estimates) over and over and over and over again to obtain numerical events from uncertainty. 

![](https://thumbs.gfycat.com/InbornTerrificAvocet-size_restricted.gif)

One type of monte carlo sampling is the bootstrap technique (this is something that I will go over in-depth when I cover random forest models in a couple of months). Bootstrapping is one of the most useful procedures in determining confidence interval parameter estimates and is a sampling technique with replacement. This means, that every time an object is sampled, it is replaced back with the same probability of independant occurance. This is especially useful when we have known/estimated probabilities of certain outcomes and we are testing with limited amounts of data. Bootstrapping has been known to be valuable in dealing with optimization when there may be heteroscedacity (errors are not normally distributed) and distributional assumptions may not be met.

In short, it's a ridiculously useful technique to create more data when we have just partial information. Well then, let's take a look at some coding!

===================================

At first, I was going to take a look at some true/false outcomes (ie. negative binomial distribution), but I thought it might be nicer to look at more complex situations.


Here's a hypothetical situation where the bootstrap & monte carlo technique may be useful:

  - Suppose your company has 4 sales areas that have a history of closing a certain probability of deals. Let's call these divisions A, B, C, and D. 

  - With phone rates being 2 cents a call, the manager was worried that their area selections are becoming obsolete and that they are going to lose revenue.

  - Because past data has shown that at least 4 percent of people who answer calls buy your product (On average, one sale makes about $199), the manager has decided that they wanted to reevaluate how costly each phone call would be and see how many calls it will take to get at least one of every single area to respond. 

  - After repeated data collection, we have observed that each division has respective probabilities of c("A" = 0.10,"B" = 0.25,"C" = 0.25,"D" = 0.40) people answering phone calls. 


**What is our estimated profit/per call?**

**Are these collective areas profitable before all fixed and variable costs (taxes, overhead, and employee compensation)?**

**Is this a valid measure of area performance?**





```{r}
library(dplyr)

numcall4 <- function(n=100) {
tha.calls <-c()
for (j in 1:n) {
  count <- 0
  A <- FALSE
  B <- FALSE
  C <- FALSE
  D <- FALSE
  while (!(A & B & C & D)) {
    count <- count + 1
    num.box <- sample(c("A", "B", "C", "D"), replace = TRUE, prob = c(0.10, 0.25, 0.25, 0.40))
      # just for fun, I did a character match with the boolean TRUE
    if (0 < sum(matches(match = "TRUE",vars = as.character(grepl("A",num.box))))) {
      A <- TRUE
    } else if (0 < sum(matches(match = "TRUE",vars = as.character(grepl("B",num.box))))) {
      B <- TRUE
    } else if (0 < sum(matches(match = "TRUE",vars = as.character(grepl("C",num.box))))) {
      C <- TRUE
    } else if (0 < sum(matches(match = "TRUE",vars = as.character(grepl("",num.box))))) {
      D <- TRUE
    }
  }
  tha.calls[j] <- sum(count)
}
mean(tha.calls) # about 40
}


```

```{r}
sale.prob <- .04 # probability of completing a sale/total answered phone calls.
ppc <- .02 # price per call
avprofit <- 199 # average profit
nReps <- 100

```


```{r}
ptm <- proc.time()  # Start the clock!

check <- c()
calls <- c()
for (i in 1:nReps) {
av_calls[i]<- numcall4()
check[i] <- sale.prob*av_calls[i]*avprofit - av_calls[i]*ppc
}
proc.time() - ptm   # Stop the clock

length(check)
mean(av_calls)
mean(check)
```

```{r}
ave_calls <- mean(av_calls)
short_profit <- mean(check)
short_profit/ave_calls 
# this means we make 7.94 cents on average per call that goes through all 4 areas.


hist(check)
mc.err <- quantile(check,c(.025,.975))
abline(v=mc.err,col='red')

c(mc.err[1],"estimate"=short_profit,mc.err[2])
```

